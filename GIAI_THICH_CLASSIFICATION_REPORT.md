# ğŸ“Š GIáº¢I THÃCH CHI TIáº¾T CLASSIFICATION REPORT

## 1. `mel_segments = np.array(mel_segments)[..., np.newaxis]`

### Shape trÆ°á»›c vÃ  sau:

```python
# TRÆ¯á»šC:
mel_segments = [segment_to_mel(seg) for seg in segments]
# Má»—i segment_to_mel() â†’ shape: (128, 87)
# Sau np.array() â†’ shape: (N, 128, 87)
# N = sá»‘ segments (vÃ­ dá»¥: 4)

# SAU:
mel_segments = np.array(mel_segments)[..., np.newaxis]
# Shape: (N, 128, 87, 1)
# ThÃªm dimension cuá»‘i = 1 (channel)
```

### Táº¡i sao cáº§n?

- **CNN yÃªu cáº§u:** `(batch, height, width, channels)`
- **Mel-spectrogram:** áº¢nh grayscale â†’ cáº§n 1 channel
- **KhÃ´ng cÃ³ channel:** Model sáº½ bÃ¡o lá»—i shape

### VÃ­ dá»¥:

```python
# 4 segments tá»« má»™t audio file:
# TrÆ°á»›c: (4, 128, 87)  â†’ âŒ Model khÃ´ng nháº­n Ä‘Æ°á»£c
# Sau:   (4, 128, 87, 1) â†’ âœ… Model nháº­n Ä‘Æ°á»£c
```

---

## 2. `classification_report` vá»›i `target_names`

```python
classification_report(
    y_true_agg,  # NhÃ£n thá»±c táº¿
    y_pred_agg,  # NhÃ£n dá»± Ä‘oÃ¡n
    target_names=[INSTRUMENT_MAP.get(x, x) for x in label_encoder_seg.classes_]
)
```

### `target_names` lÃ m gÃ¬?

- **Äá»•i tÃªn class** tá»« code â†’ tÃªn Ä‘áº§y Ä‘á»§ (dá»… Ä‘á»c)
- **INSTRUMENT_MAP:** `{'cel': 'Cello', 'cla': 'Clarinet', ...}`
- **label_encoder_seg.classes_:** `['cel', 'cla', 'flu', ...]`
- **Káº¿t quáº£:** `['Cello', 'Clarinet', 'Flute', ...]`

### VÃ­ dá»¥:

```
# KHÃ”NG cÃ³ target_names:
cel          0.68      0.91      0.78        78  â† KhÃ³ Ä‘á»c

# CÃ“ target_names:
Cello        0.68      0.91      0.78        78  â† Dá»… Ä‘á»c!
```

---

## 3. GIáº¢I THÃCH CÃC THÃ”NG Sá»

### VÃ­ dá»¥ Classification Report:

```
                 precision    recall  f1-score   support

          Cello       0.68      0.91      0.78        78
       Clarinet       0.79      0.80      0.79       101
          Flute       0.78      0.78      0.78        90
Acoustic Guitar       0.87      0.91      0.89       127
Electric Guitar       0.82      0.85      0.83       152
          Organ       0.85      0.97      0.90       136
          Piano       0.92      0.91      0.92       144
      Saxophone       0.77      0.70      0.73       125
        Trumpet       0.95      0.85      0.90       116
         Violin       0.89      0.61      0.72       116
          Voice       0.94      0.95      0.94       156

       accuracy                           0.85      1341
      macro avg       0.84      0.84      0.84      1341
   weighted avg       0.85      0.85      0.84      1341
```

---

### ğŸ“Š CÃC Cá»˜T:

#### 1. **Precision (Äá»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n)**

**CÃ´ng thá»©c:**
```
Precision = TP / (TP + FP)
```

**Ã nghÄ©a:**
- Trong sá»‘ cÃ¡c máº«u model dá»± Ä‘oÃ¡n lÃ  class Ä‘Ã³, bao nhiÃªu % lÃ  Ä‘Ãºng?
- **VÃ­ dá»¥ Cello (0.68 = 68%):**
  - Model dá»± Ä‘oÃ¡n 100 máº«u lÃ  Cello
  - Trong Ä‘Ã³ 68 máº«u thá»±c sá»± lÃ  Cello
  - â†’ Precision = 68/100 = 0.68

**Giáº£i thÃ­ch:**
- **Precision cao** â†’ Model Ã­t dá»± Ä‘oÃ¡n sai (khi nÃ³i "Cello" thÃ¬ Ä‘Ãºng lÃ  Cello)
- **Precision tháº¥p** â†’ Model dá»± Ä‘oÃ¡n sai nhiá»u (nÃ³i "Cello" nhÆ°ng khÃ´ng pháº£i)

---

#### 2. **Recall (Äá»™ nháº¡y)**

**CÃ´ng thá»©c:**
```
Recall = TP / (TP + FN)
```

**Ã nghÄ©a:**
- Trong sá»‘ cÃ¡c máº«u thá»±c táº¿ lÃ  class Ä‘Ã³, model tÃ¬m Ä‘Æ°á»£c bao nhiÃªu %?
- **VÃ­ dá»¥ Cello (0.91 = 91%):**
  - CÃ³ 78 máº«u thá»±c táº¿ lÃ  Cello
  - Model tÃ¬m Ä‘Æ°á»£c 71 máº«u (91%)
  - â†’ Recall = 71/78 = 0.91

**Giáº£i thÃ­ch:**
- **Recall cao** â†’ Model Ã­t bá» sÃ³t (tÃ¬m Ä‘Æ°á»£c háº§u háº¿t cÃ¡c máº«u thá»±c táº¿)
- **Recall tháº¥p** â†’ Model bá» sÃ³t nhiá»u (cÃ³ máº«u lÃ  Cello nhÆ°ng khÃ´ng tÃ¬m Ä‘Æ°á»£c)

---

#### 3. **F1-Score (Trung bÃ¬nh Ä‘iá»u hÃ²a)**

**CÃ´ng thá»©c:**
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**Ã nghÄ©a:**
- Káº¿t há»£p cáº£ Precision vÃ  Recall
- **VÃ­ dá»¥ Cello:**
  - Precision = 0.68, Recall = 0.91
  - F1 = 2 Ã— (0.68 Ã— 0.91) / (0.68 + 0.91) = 0.78

**Giáº£i thÃ­ch:**
- **F1 cao** â†’ Cáº£ Precision vÃ  Recall Ä‘á»u tá»‘t
- **F1 tháº¥p** â†’ Má»™t trong hai (hoáº·c cáº£ hai) tháº¥p

---

#### 4. **Support (Sá»‘ lÆ°á»£ng máº«u)**

**Ã nghÄ©a:**
- Sá»‘ lÆ°á»£ng máº«u thá»±c táº¿ cá»§a class Ä‘Ã³ trong test set
- **VÃ­ dá»¥ Cello: 78 máº«u**

---

### ğŸ“ˆ PHÃ‚N TÃCH VÃ Dá»¤ (CELLO):

```
Cello: precision=0.68, recall=0.91, f1=0.78, support=78
```

**Giáº£i thÃ­ch:**
- **Precision 0.68 (68%):**
  - Khi model dá»± Ä‘oÃ¡n "Cello", 68% lÃ  Ä‘Ãºng
  - 32% lÃ  sai (cÃ³ thá»ƒ nháº§m vá»›i Violin, Organ, ...)
- **Recall 0.91 (91%):**
  - Trong 78 máº«u Cello thá»±c táº¿, model tÃ¬m Ä‘Æ°á»£c 91% (â‰ˆ71 máº«u)
  - Bá» sÃ³t 9% (â‰ˆ7 máº«u)
- **F1 0.78:**
  - CÃ¢n báº±ng giá»¯a Precision vÃ  Recall
  - Model tÃ¬m Ä‘Æ°á»£c nhiá»u Cello (Recall cao) nhÆ°ng Ä‘Ã´i khi nháº§m (Precision tháº¥p)

**Káº¿t luáº­n:**
- Model **tÃ¬m Ä‘Æ°á»£c nhiá»u Cello** (Recall cao = 91%)
- NhÆ°ng **Ä‘Ã´i khi nháº§m** (Precision tháº¥p = 68%)
- â†’ Cáº§n cáº£i thiá»‡n Precision (giáº£m false positives)

---

### ğŸ“Š CÃC DÃ’NG Tá»”NG Há»¢P:

#### 1. **Accuracy (Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ)**

```
accuracy = 0.85 (85%)
```

**CÃ´ng thá»©c:**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**Ã nghÄ©a:**
- Trong táº¥t cáº£ 1341 máº«u test, model dá»± Ä‘oÃ¡n Ä‘Ãºng 85%
- â†’ 1140 máº«u Ä‘Ãºng, 201 máº«u sai

---

#### 2. **Macro Average (Trung bÃ¬nh Ä‘Æ¡n giáº£n)**

```
macro avg: precision=0.84, recall=0.84, f1=0.84
```

**CÃ´ng thá»©c:**
```
Macro Precision = (Precision_1 + Precision_2 + ... + Precision_11) / 11
```

**Ã nghÄ©a:**
- Trung bÃ¬nh Ä‘Æ¡n giáº£n cá»§a táº¥t cáº£ classes
- **KhÃ´ng quan tÃ¢m** Ä‘áº¿n sá»‘ lÆ°á»£ng máº«u cá»§a má»—i class
- **Äá»‘i xá»­ cÃ´ng báº±ng** vá»›i táº¥t cáº£ classes

**VÃ­ dá»¥:**
```
Macro Precision = (0.68 + 0.79 + 0.78 + ... + 0.94) / 11 â‰ˆ 0.84
```

---

#### 3. **Weighted Average (Trung bÃ¬nh cÃ³ trá»ng sá»‘)**

```
weighted avg: precision=0.85, recall=0.85, f1=0.84
```

**CÃ´ng thá»©c:**
```
Weighted Precision = Î£(Precision_i Ã— Support_i) / Î£(Support_i)
```

**Ã nghÄ©a:**
- Trung bÃ¬nh cÃ³ trá»ng sá»‘ theo sá»‘ lÆ°á»£ng máº«u
- **Classes cÃ³ nhiá»u máº«u** â†’ Trá»ng sá»‘ cao hÆ¡n
- **Pháº£n Ã¡nh tá»‘t hÆ¡n** hiá»‡u suáº¥t thá»±c táº¿ (vÃ¬ Æ°u tiÃªn classes cÃ³ nhiá»u data)

**VÃ­ dá»¥:**
```
Weighted Precision = (0.68Ã—78 + 0.79Ã—101 + ... + 0.94Ã—156) / 1341 â‰ˆ 0.85
```

**Táº¡i sao Weighted > Macro?**
- Classes cÃ³ nhiá»u máº«u (Voice: 156, Electric Guitar: 152) cÃ³ Precision cao
- â†’ Weighted Average cao hÆ¡n Macro Average

---

## ğŸ¯ SO SÃNH MACRO vs WEIGHTED:

| Metric | Macro Avg | Weighted Avg |
|--------|-----------|--------------|
| **CÃ¡ch tÃ­nh** | Trung bÃ¬nh Ä‘Æ¡n giáº£n | Trung bÃ¬nh cÃ³ trá»ng sá»‘ |
| **Æ¯u tiÃªn** | Táº¥t cáº£ classes Ä‘á»u nhau | Classes cÃ³ nhiá»u máº«u |
| **PhÃ¹ há»£p** | Class balance | Class imbalance |
| **Káº¿t quáº£** | 0.84 | 0.85 |

**Trong Ä‘á»“ Ã¡n nÃ y:**
- Dataset cÃ³ **class imbalance** (Voice: 156, Cello: 78)
- â†’ **Weighted Average** pháº£n Ã¡nh tá»‘t hÆ¡n hiá»‡u suáº¥t thá»±c táº¿

---

## ğŸ“‹ TÃ“M Táº®T:

1. **`[..., np.newaxis]`:** ThÃªm channel dimension (1) â†’ Shape: (N, 128, 87, 1)
2. **`target_names`:** Äá»•i tÃªn class tá»« code â†’ tÃªn Ä‘áº§y Ä‘á»§
3. **Precision:** Äá»™ chÃ­nh xÃ¡c khi dá»± Ä‘oÃ¡n class Ä‘Ã³
4. **Recall:** Tá»· lá»‡ tÃ¬m Ä‘Æ°á»£c cÃ¡c máº«u thá»±c táº¿
5. **F1-Score:** CÃ¢n báº±ng giá»¯a Precision vÃ  Recall
6. **Support:** Sá»‘ lÆ°á»£ng máº«u thá»±c táº¿
7. **Macro Avg:** Trung bÃ¬nh Ä‘Æ¡n giáº£n (Ä‘á»‘i xá»­ cÃ´ng báº±ng)
8. **Weighted Avg:** Trung bÃ¬nh cÃ³ trá»ng sá»‘ (Æ°u tiÃªn classes cÃ³ nhiá»u máº«u)

