# Musical Instrument Recognition Demo

ChÆ°Æ¡ng trÃ¬nh demo nháº­n dáº¡ng nháº¡c cá»¥ sá»­ dá»¥ng model Ä‘Ã£ train trÃªn IRMAS dataset.

## ğŸ“‹ YÃªu cáº§u

- Python 3.8+
- CÃ¡c thÆ° viá»‡n trong `requirements.txt`

## ğŸš€ CÃ i Ä‘áº·t

1. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:
```bash
pip install -r requirements.txt
```

2. Äáº£m báº£o cÃ¡c file model cÃ³ trong thÆ° má»¥c `IRMAS_Models/`:
   - **CNN Model:**
     - `best_segment_cnn.keras` - Model CNN segment-based
     - `label_encoder_seg.joblib` - Label encoder cho CNN
     - `segment_config.joblib` - Config cho segment-based (tÃ¹y chá»n)
   - **SVM Model:**
     - `svm_instrument_model.joblib` - SVM pipeline (scaler, selector, model, label_encoder)
     - `label_encoder_svm.joblib` - Label encoder cho SVM (tÃ¹y chá»n, cÃ³ thá»ƒ láº¥y tá»« pipeline)

## ğŸ’» Sá»­ dá»¥ng

Cháº¡y chÆ°Æ¡ng trÃ¬nh:
```bash
python instrument_recognition_demo.py
```

## ğŸ¯ Chá»©c nÄƒng

### 1. **Open File**
- Má»Ÿ file audio (.wav) tá»« disk
- Há»— trá»£ cÃ¡c sample rate khÃ¡c nhau (tá»± Ä‘á»™ng resample vá» 22050 Hz)

### 2. **Record**
- Thu Ã¢m tá»« microphone
- Ghi vÃ o file `recorded_audio.wav`
- Sample rate: 22050 Hz, mono channel

### 3. **Stop**
- Dá»«ng quÃ¡ trÃ¬nh thu Ã¢m

### 4. **Play**
- PhÃ¡t láº¡i audio Ä‘Ã£ load/record

### 5. **Prediction Method Selection**
- Chá»n phÆ°Æ¡ng phÃ¡p nháº­n dáº¡ng:
  - **CNN (Segment-based)**: Deep Learning vá»›i Mel-Spectrogram vÃ  segment aggregation
  - **SVM (Handcrafted)**: Traditional ML vá»›i handcrafted features (MFCC, spectral features)

### 6. **Predict**
- Dá»± Ä‘oÃ¡n nháº¡c cá»¥ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Ä‘Ã£ chá»n
- Hiá»ƒn thá»‹:
  - Nháº¡c cá»¥ dá»± Ä‘oÃ¡n (top-1)
  - Confidence score
  - Top-3 predictions vá»›i confidence
  - Sá»‘ segments (náº¿u dÃ¹ng CNN)

## ğŸ¼ CÃ¡c nháº¡c cá»¥ Ä‘Æ°á»£c nháº­n dáº¡ng

1. **Cello** (cel)
2. **Clarinet** (cla)
3. **Flute** (flu)
4. **Acoustic Guitar** (gac)
5. **Electric Guitar** (gel)
6. **Organ** (org)
7. **Piano** (pia)
8. **Saxophone** (sax)
9. **Trumpet** (tru)
10. **Violin** (vio)
11. **Voice** (voi)

## âš™ï¸ Hai PhÆ°Æ¡ng PhÃ¡p Nháº­n Dáº¡ng

### 1. **CNN (Segment-based)** - Deep Learning

#### Mel-Spectrogram Parameters
```python
sr = 22050          # Sample rate (Hz)
n_fft = 2048        # FFT window size
hop_length = 512    # Hop length between frames
n_mels = 128        # Number of mel filter banks
```

#### Segment-Based Parameters
```python
segment_duration = 2.0    # Äá»™ dÃ i má»—i segment (giÃ¢y)
segment_overlap = 0.5     # Overlap ratio (50%) cho sliding window
```

**Input shape cá»§a CNN model:** `(128, 87, 1)`
- 128: sá»‘ mel bins
- 87: sá»‘ time frames (tÆ°Æ¡ng á»©ng vá»›i segment 2.0s)
- 1: channel (grayscale)

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. Audio Ä‘Æ°á»£c cáº¯t thÃ nh nhiá»u segments 2.0s vá»›i sliding window (overlap 50%)
2. Má»—i segment Ä‘Æ°á»£c chuyá»ƒn thÃ nh mel-spectrogram
3. CNN predict tá»«ng segment
4. **Average softmax** cá»§a táº¥t cáº£ segments â†’ káº¿t quáº£ cuá»‘i cÃ¹ng

**Æ¯u Ä‘iá»ƒm:**
- âœ… Accuracy cao hÆ¡n (~85%)
- âœ… Robust vá»›i audio dÃ i
- âœ… Táº­n dá»¥ng toÃ n bá»™ thÃ´ng tin trong audio

### 2. **SVM (Handcrafted Features)** - Traditional ML

#### Features Ä‘Æ°á»£c trÃ­ch xuáº¥t:
- **MFCC** (40 coefficients): mean, std, max, min
- **Delta & Delta-Delta** cá»§a MFCC
- **Spectral features**: centroid, bandwidth, rolloff, flatness
- **Spectral contrast, Chroma, Tonnetz**
- **Zero crossing rate, RMS**

**Tá»•ng cá»™ng:** 382 features

#### CÃ¡ch hoáº¡t Ä‘á»™ng:
1. TrÃ­ch xuáº¥t handcrafted features tá»« toÃ n bá»™ audio
2. Normalize vÃ  select features (SelectKBest vá»›i k=100)
3. SVM predict trá»±c tiáº¿p

**Æ¯u Ä‘iá»ƒm:**
- âœ… Nhanh hÆ¡n CNN
- âœ… KhÃ´ng cáº§n GPU
- âœ… Accuracy ~74%

## ğŸ”§ Äiá»u chá»‰nh cho model khÃ¡c

Náº¿u báº¡n sá»­ dá»¥ng model vá»›i cáº¥u trÃºc khÃ¡c, cáº§n thay Ä‘á»•i:

### 1. **CNN Parameters** (dÃ²ng 44-57):
```python
self.sr = 22050          # Sample rate
self.n_fft = 2048        # FFT window size
self.hop_length = 512    # Hop length
self.n_mels = 128       # Mel filter banks
self.segment_duration = 2.0  # Segment duration (tá»± Ä‘á»™ng load tá»« config)
```

### 2. **SVM Parameters** (dÃ²ng 48):
```python
self.n_mfcc = 40        # Sá»‘ MFCC coefficients
```

### 3. **Model paths** (trong hÃ m `load_models()`):
```python
# CNN
cnn_model_path = "IRMAS_Models/best_segment_cnn.keras"
cnn_label_encoder_path = "IRMAS_Models/label_encoder_seg.joblib"

# SVM
svm_model_path = "IRMAS_Models/svm_instrument_model.joblib"
svm_label_encoder_path = "IRMAS_Models/label_encoder_svm.joblib"
```

### 4. **Label mapping** (dÃ²ng 68-81):
```python
self.instrument_names = {
    'cel': 'Cello',
    'cla': 'Clarinet',
    # ... thÃªm/sá»­a cÃ¡c nháº¡c cá»¥ khÃ¡c
}
```

## ğŸ“ LÆ°u Ã½

1. **Audio quality**: Äá»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t, audio nÃªn:
   - CÃ³ Ä‘á»™ dÃ i tá»‘i thiá»ƒu 1-2 giÃ¢y
   - Cháº¥t lÆ°á»£ng rÃµ rÃ ng, Ã­t noise
   - Nháº¡c cá»¥ phÃ¡t ra Ã¢m thanh rÃµ rÃ ng

2. **Sample rate**: Audio sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c resample vá» 22050 Hz náº¿u cáº§n

3. **Real-time**: Hiá»‡n táº¡i chÆ°Æ¡ng trÃ¬nh xá»­ lÃ½ offline. Äá»ƒ chuyá»ƒn sang real-time:
   - Sá»­ dá»¥ng sliding window
   - Xá»­ lÃ½ tá»«ng chunk audio
   - Cáº­p nháº­t prediction liÃªn tá»¥c

## ğŸ› Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### Lá»—i: "Model file not found"
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n Ä‘áº¿n file model
- Äáº£m báº£o file `best_cnn_model.keras` tá»“n táº¡i trong `IRMAS_Models/`

### Lá»—i: "Failed to load models"
- Kiá»ƒm tra version cá»§a TensorFlow/Keras
- Äáº£m báº£o model Ä‘Æ°á»£c save Ä‘Ãºng format

### Lá»—i: "No audio to play"
- Record hoáº·c má»Ÿ file audio trÆ°á»›c khi play/predict

### Lá»—i khi predict: Shape mismatch
- Kiá»ƒm tra input shape cá»§a model
- Äáº£m báº£o mel-spectrogram parameters khá»›p vá»›i lÃºc training

## ğŸ“š Cáº¥u trÃºc code

- `InstrumentRecognitionApp`: Class chÃ­nh chá»©a UI vÃ  logic
- `load_models()`: Load model vÃ  label encoder
- `record_audio()`: Thu Ã¢m tá»« microphone
- `open_file()`: Má»Ÿ file audio
- `play_audio()`: PhÃ¡t láº¡i audio
- `extract_mel_spectrogram()`: TrÃ­ch xuáº¥t features
- `prepare_input()`: Chuáº©n bá»‹ input cho model
- `predict_instrument()`: Dá»± Ä‘oÃ¡n vÃ  hiá»ƒn thá»‹ káº¿t quáº£

## ğŸ”® Má»Ÿ rá»™ng

CÃ³ thá»ƒ má»Ÿ rá»™ng thÃªm:
- Hiá»ƒn thá»‹ Mel-Spectrogram visualization
- Real-time streaming prediction
- Export káº¿t quáº£ ra file
- Batch processing nhiá»u file
- So sÃ¡nh vá»›i ground truth labels

